{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import pandas as pd\n",
    "from src.preprocessing import Preprocessor\n",
    "from src.feature_engineering import FeatureCreator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/raw/Suicide_Detection.csv', usecols=['text','class'])\n",
    "df['class'] = df['class'].map({'suicide': 1, 'non-suicide':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_preclean = [\n",
    "    \"get_length\", \n",
    "    \"get_exclamation_count\"\n",
    "]\n",
    "\n",
    "feature_creator_preclean = FeatureCreator(procedure=procedure_preclean)\n",
    "length_exclamation = [feature_creator_preclean.fit(document) for document in df['text']]\n",
    "length = [x for x,y in length_exclamation]\n",
    "exclamation = [y for x,y in length_exclamation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_feature_preclean = {\n",
    "    'length': length,\n",
    "    'exclamation': exclamation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_config = {\n",
    "    \"1\": ['lower', 'remove_punctuation', 'remove_links', 'remove_numbers', \n",
    "    'remove_emoji', 'tokenize', 'remove_stopwords', 'stem', 'lemmatize', \n",
    "    'remove_short_words', 'remove_long_words', 'shorten_text'],\n",
    "\n",
    "    \"2\": ['lower', 'remove_punctuation', 'remove_links', 'remove_numbers',\n",
    "    'translate_emoji', 'tokenize', 'remove_stopwords', 'stem', 'lemmatize', \n",
    "    'remove_short_words', 'remove_long_words', 'shorten_text'],\n",
    "\n",
    "    \"3\": ['lower', 'remove_punctuation', 'remove_links', 'remove_numbers',\n",
    "    'translate_emoji', 'tokenize', 'remove_stopwords', 'stem', 'lemmatize', \n",
    "    'remove_short_words', 'remove_long_words'],\n",
    "\n",
    "    \"4\": ['lower', 'remove_punctuation', 'remove_links', 'remove_numbers',\n",
    "    'translate_emoji', 'tokenize', 'remove_stopwords', 'stem', 'lemmatize', \n",
    "    'remove_short_words'],\n",
    "\n",
    "    \"5\": ['lower', 'remove_punctuation', 'remove_links', 'remove_numbers',\n",
    "    'translate_emoji', 'tokenize', 'remove_stopwords', 'stem', 'lemmatize'],\n",
    "\n",
    "    \"6\": ['lower', 'remove_punctuation', 'remove_links', 'remove_numbers',\n",
    "    'translate_emoji', 'tokenize', 'remove_stopwords', 'stem'],\n",
    "    \n",
    "    \"7\": ['lower', 'remove_punctuation', 'remove_links', 'remove_numbers',\n",
    "    'translate_emoji', 'tokenize', 'remove_stopwords', 'lemmatize'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering_preclean_config = {\n",
    "    \"1\": ['length', 'exclamation_count'],\n",
    "    \"2\": ['length'],\n",
    "    \"3\": ['exclamation_count'],\n",
    "}\n",
    "\n",
    "feature_engineering_postclean_config = {\n",
    "    \"1\": ['get_sentiment','get_keyword'],\n",
    "    \"2\": ['get_sentiment'],\n",
    "    \"3\": ['get_keyword'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    # \"naive_bayes\": MultinomialNB(),\n",
    "    \"svm\": SVC(),\n",
    "    \"knn\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"RandomForest\": RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done!\n",
      "Vectorizer ready!\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "preprocessing = Preprocessor(procedure=preprocessing_config['1'])\n",
    "corpus = df['text'].apply(lambda x: preprocessing.fit(x))\n",
    "y = df['class'][corpus.astype(bool)]\n",
    "corpus = corpus[corpus.astype(bool)]\n",
    "print('Preprocessing done!')\n",
    "\n",
    "# feature engineering after preprocessing\n",
    "feature_creator_postclean = FeatureCreator(procedure=feature_engineering_postclean_config['1'])\n",
    "feature_creator_postclean.fit_vectorizer(corpus)\n",
    "print('Vectorizer ready!')\n",
    "sentiment_keyword = [feature_creator_postclean.fit(document) for document in corpus]\n",
    "sentiment = [x for x,y in sentiment_keyword]\n",
    "keyword = [y for x,y in sentiment_keyword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: svm\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x.drop('class',axis=1), df_x['class'], test_size=0.2, random_state=42)\n",
    "\n",
    "for model_name, model in models_config.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Training score: {model.score(X_train, y_train)}\")\n",
    "    print(f\"Testing score: {model.score(X_test, y_test)}\")\n",
    "    print(f\"Cross validation score: {cross_val_score(model, df_x, df_x['class'], cv=5)}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d66d549bdef250af71f18e523f93ac3dcbb8bf027e6088d6eb631521c6a7e128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
