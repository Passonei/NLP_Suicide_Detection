{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suicide_detection = pd.read_csv('../../data/prepared/prepared.csv').drop('Unnamed: 0',axis=1)\n",
    "df_suicide_detection['corpus'] = df_suicide_detection['corpus'].apply(lambda x: x[1:-1].replace(\"'\", \"\").split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    text = ' '.join(text)\n",
    "    sentiment = sid.polarity_scores(text)\n",
    "    return sentiment\n",
    "\n",
    "df_suicide_detection['sentiment'] = df_suicide_detection['corpus'].apply(sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_suicide</th>\n",
       "      <th>suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>0.154675</td>\n",
       "      <td>0.265312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu</th>\n",
       "      <td>0.629486</td>\n",
       "      <td>0.540684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>0.215837</td>\n",
       "      <td>0.194007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>0.124115</td>\n",
       "      <td>-0.353753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          non_suicide   suicide\n",
       "neg          0.154675  0.265312\n",
       "neu          0.629486  0.540684\n",
       "pos          0.215837  0.194007\n",
       "compound     0.124115 -0.353753"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df_suicide_detection.groupby(df_suicide_detection['class'])['sentiment'].apply(list).reset_index()\n",
    "\n",
    "df_sentiment = pd.concat([\n",
    "    pd.DataFrame(grouped['sentiment'].iloc[0]).mean(),\n",
    "    pd.DataFrame(grouped['sentiment'].iloc[1]).mean()],\n",
    "axis=1,\n",
    ")\n",
    "df_sentiment.columns=['non_suicide','suicide']\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suicide-related texts show a higher level of negative sentiment (26.53%) compared to non-suicide-related texts (15.47%). This suggests that texts related to suicide contain more negative content. Texts unrelated to suicide have a slightly higher level of neutral sentiment (62.95%) compared to texts related to suicide (54.07%). Texts related to suicide contain more neutral content. The level of positive sentiment is similar for both categories.\n",
    "\n",
    "Total Indicator (Compound): The average composite index is positive for non-suicide-related texts (12.41%), indicating a slightly positive trend. In contrast, for texts related to suicide, the index is significantly negative (-35.38%), suggesting a higher level of overall negative sentiment.\n",
    "\n",
    "Sentiment analysis shows that texts related to suicide contain more negative content compared to unrelated texts, which show a slightly higher level of positive sentiment and a lower level of overall negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification of extreme cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely negative:\n",
      "                                                   corpus  class\n",
      "349     [want, end, myselfsad, pain, sad, pain, sad, p...      1\n",
      "1118    [tried, kill, nighti, dont, really, know, talk...      1\n",
      "1235    [final, wordsi, finally, decided, commit, suic...      1\n",
      "2653    [hate, feel, deserve, feel, way, dont, deserve...      1\n",
      "2719    [warning, suicide, nobody, read, thismy, name,...      1\n",
      "...                                                   ...    ...\n",
      "229285  [want, fuck, fuck, fuck, fuck, fuck, fuck, fuc...      0\n",
      "229767  [advice, neededi, would, like, advice, situati...      1\n",
      "230676  [updatetldr, bottom, post, survived, attempt, ...      1\n",
      "230727  [recent, painful, graduation, subreddit, hey, ...      0\n",
      "231636  [suicidal, begging, help, turned, away, retali...      1\n",
      "\n",
      "[310 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "extremely_negative = df_suicide_detection[df_suicide_detection['sentiment'].apply(lambda x: x['compound'] < -0.999)]\n",
    "\n",
    "print(\"Extremely negative:\")\n",
    "print(extremely_negative[['corpus', 'class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely positive:\n",
      "                                                   corpus  class\n",
      "3755    [plz, message, meplz, plz, plz, plz, plz, plz,...      1\n",
      "4182    [talk, mei, need, lp, need, help, need, help, ...      1\n",
      "5227    [casual, reminder, le, hour, left, global, mas...      0\n",
      "6044    [originally, posted, throw, away, might, well,...      1\n",
      "12008   [need, help, sure, say, feel, like, need, get,...      0\n",
      "...                                                   ...    ...\n",
      "219944  [best, friend, crushed, passion, life, destroy...      1\n",
      "222349  [please, kill, meplease, please, please, pleas...      1\n",
      "229122  [dont, let, lust, take, love, oh, boy, even, s...      0\n",
      "230263  [screwed, everything, lost, best, friendfirst,...      1\n",
      "231129  [sacred, text, talk, girlshow, get, girlfriend...      0\n",
      "\n",
      "[106 rows x 2 columns]\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "extremely_positive = df_suicide_detection[df_suicide_detection['sentiment'].apply(lambda x: x['compound'] > 0.999)]\n",
    "\n",
    "print(\"Extremely positive:\")\n",
    "print(extremely_positive[['corpus', 'class']])\n",
    "print(len(extremely_positive[extremely_positive['class']==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40 Examples that were marked as extremely positive, but are related to the topic of suicide (1=suicide), may be the result of sentiment incorrectly assigned due to context or sentence structure. It is likely that the sentiment analysis algorithm may have made an identification error by focusing on individual words rather than the context of the entire sentence or text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremely positive cases include those belonging to the \"suicide\" class containing cries for help.  \n",
    "Sentiment correction for the word \"help\" nad some words from the thematic analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_sentiment(text, sentiment):\n",
    "    help_words = ['help', 'pleas', 'plz',\n",
    "    'suicide','ibuprofen']\n",
    "    \n",
    "    if any(word in (text) for word in help_words) and sentiment > 0: \n",
    "        return sentiment-0.3 \n",
    "    return sentiment \n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    text = \" \".join(text)\n",
    "    sentiment = sid.polarity_scores(text)\n",
    "    if 'help' in str(text) or 'please' in text and sentiment>0:\n",
    "        sentiment['compound'] -= 0.3 \n",
    "    return sentiment\n",
    "\n",
    "df_suicide_detection['adjusted_sentiment'] = df_suicide_detection.apply(lambda row: adjust_sentiment(' '.join(row['corpus']), row['sentiment']['compound']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_suicide</th>\n",
       "      <th>suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.098746</td>\n",
       "      <td>-0.394805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   non_suicide   suicide\n",
       "0     0.098746 -0.394805"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df_suicide_detection.groupby(df_suicide_detection['class'])['adjusted_sentiment'].apply(list).reset_index()\n",
    "\n",
    "df_sentiment = pd.concat([\n",
    "    pd.DataFrame(grouped['adjusted_sentiment'].iloc[0]).mean(),\n",
    "    pd.DataFrame(grouped['adjusted_sentiment'].iloc[1]).mean()],\n",
    "axis=1,\n",
    ")\n",
    "df_sentiment.columns=['non_suicide','suicide']\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely positive:\n",
      "                                                   corpus  class\n",
      "15740   [boy, kissed, boy, kissed, also, pretty, long,...      0\n",
      "15959   [read, love, love, love, love, love, love, lov...      0\n",
      "17501   [calling, beautiful, understand, beautiful, pi...      0\n",
      "17888   [slept, cousinÂ´s, sister, yes, im, actual, tee...      0\n",
      "47129   [ever, sad, remember, world, glam, punk, love,...      0\n",
      "48636   [solid, man, penetrates, water, like, solid, f...      0\n",
      "51227   [reminder, kid, eat, rich, eat, rich, eat, ric...      0\n",
      "87115   [find, pizza, pizza, gt, smiling_face_with_ope...      0\n",
      "100531  [know, yall, struggling, wow, wow, wow, wow, w...      0\n",
      "114976  [speech, wrote, happy, join, today, go, histor...      0\n",
      "143097  [calling, beautiful, till, understand, beautif...      0\n",
      "144639  [ok, girl, met, back, talking, friend, however...      0\n",
      "155417  [school, motto, kinda, cringe, care, share, da...      0\n",
      "156445  [katy, perry, gush, hey, guy, gal, non, binary...      0\n",
      "163572  [manchester, uk, looking, friendship, preferab...      0\n",
      "164641  [merry, christmas, merry, christmas, evergreen...      0\n",
      "170704  [copypasta, im, six, pardon, grammar, ive, nas...      0\n",
      "177059  [mf, like, mf, like, mf, like, mf, like, mf, l...      0\n",
      "178543  [love, love, love, love, love, love, love, lov...      0\n",
      "183037  [today, day, weird, day, happened, lot, thing,...      0\n",
      "206464  [george, floyd, moment, xd, xd, xd, xd, xd, xd...      0\n",
      "216015  [asked, crush, well, never, one, since, sub, t...      0\n",
      "219944  [best, friend, crushed, passion, life, destroy...      1\n"
     ]
    }
   ],
   "source": [
    "extremely_positive = df_suicide_detection[df_suicide_detection['adjusted_sentiment'].apply(lambda x: x > 0.999)]\n",
    "\n",
    "print(\"Extremely positive:\")\n",
    "print(extremely_positive[['corpus', 'class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between text length and sentiment: -0.1330076893723232\n"
     ]
    }
   ],
   "source": [
    "correlation = pd.Series([len(x) for x in df_suicide_detection['corpus']]).corr(df_suicide_detection['adjusted_sentiment'])\n",
    "print(f\"Correlation between text length and sentiment: {correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation of -0.133 suggests a weak but negative relationship between text length and sentiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d66d549bdef250af71f18e523f93ac3dcbb8bf027e6088d6eb631521c6a7e128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
