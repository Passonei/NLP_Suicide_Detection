{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suicide_detection = pd.read_csv('../../data/prepared/prepared_2.csv').drop('Unnamed: 0',axis=1)\n",
    "df_suicide_detection['corpus'] = df_suicide_detection['corpus'].apply(lambda x: x[1:-1].replace(\"'\", \"\").split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    text = ' '.join(text)\n",
    "    sentiment = sid.polarity_scores(text)\n",
    "    return sentiment\n",
    "\n",
    "df_suicide_detection['sentiment'] = df_suicide_detection['corpus'].apply(sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_suicide</th>\n",
       "      <th>suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>0.143912</td>\n",
       "      <td>0.214827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu</th>\n",
       "      <td>0.679522</td>\n",
       "      <td>0.620980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>0.176567</td>\n",
       "      <td>0.164190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>0.069729</td>\n",
       "      <td>-0.247926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          non_suicide   suicide\n",
       "neg          0.143912  0.214827\n",
       "neu          0.679522  0.620980\n",
       "pos          0.176567  0.164190\n",
       "compound     0.069729 -0.247926"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df_suicide_detection.groupby(df_suicide_detection['class'])['sentiment'].apply(list).reset_index()\n",
    "\n",
    "df_sentiment = pd.concat([\n",
    "    pd.DataFrame(grouped['sentiment'].iloc[0]).mean(),\n",
    "    pd.DataFrame(grouped['sentiment'].iloc[1]).mean()],\n",
    "axis=1,\n",
    ")\n",
    "df_sentiment.columns=['non_suicide','suicide']\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the 'suicide' category has a higher negative sentiment (0.214) than the 'non_suicide' category (0.143).   \n",
    "The positive indices are similar.    \n",
    "Compound is the overall sentiment value. It is lower in 'suicide' (-0.247) than in 'non_suicide' (0.069).  \n",
    "Overall sentiment context in terms of 'suicide' is more inclined toward negativity compared to 'non_suicide'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification of extreme cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely negative:\n",
      "                                                   corpus  class\n",
      "349     [want, end, myselfsad, pain, sad, pain, sad, p...      1\n",
      "3457    [meow, cat, unmut, zoom, fuck, fuck, fuck, fuc...      0\n",
      "4851    [fuck, mess, much, time, nsfw, due, languageco...      1\n",
      "5130    [fuck, ghod, go, shtit, abnd, cum, nmi, teache...      0\n",
      "8055    [easier, kill, traumai, wan, fuck, km, bad, ha...      1\n",
      "10313   [turn, soon, fuckkmg, terrifi, might, attract,...      1\n",
      "11816   [predict, feel, shit, fuck, shit, fuck, shit, ...      0\n",
      "25015   [unwant, unwant, unwant, unlov, unlov, cure, c...      1\n",
      "30226   [hurtshurt, hurt, hurt, hurt, hurt, hurt, hurt...      1\n",
      "39243   [exist, fuck, nightmareeveri, fuck, time, some...      1\n",
      "39309   [fuck, brice, maddock, fuck, brice, maddock, f...      0\n",
      "42334   [fuck, fuck, fuck, fuck, fuckfuck, fuck, fuck,...      1\n",
      "43714   [need, let, anger, fuck, fuck, fuck, shit, fuc...      0\n",
      "45389   [kill, pleasejust, kill, kill, kill, kill, kil...      1\n",
      "48111   [kill, mekil, kill, kill, kill, kill, kill, ki...      1\n",
      "48366   [want, kill, good, reason, toonot, even, reddi...      1\n",
      "53100   [petit, make, shit, fuck, shit, fuck, shit, fu...      0\n",
      "55965   [fuck, sake, let, fuck, diei, dont, want, fuck...      1\n",
      "58156   [stori, time, child, one, hot, ass, mother, fu...      0\n",
      "59891   [wan, die, wan, die, wan, die, wan, die, wan, ...      1\n",
      "61610   [fuck, fuck, fuck, fuck, fuck, fuck, fuck, fuc...      0\n",
      "71316   [let, dielet, die, let, die, let, die, let, di...      1\n",
      "84406   [thatwhat, fuck, parent, fuck, childim, hurt, ...      1\n",
      "87834   [therapeut, ass, popper, gtass, ass, ass, ass,...      0\n",
      "91312   [start, write, thought, occur, panic, attack, ...      1\n",
      "97420   [want, diei, want, die, want, die, want, die, ...      1\n",
      "106242  [want, diei, want, die, want, die, want, die, ...      1\n",
      "113230  [hmmmi, want, die, want, die, want, die, want,...      1\n",
      "117945  [realli, hate, myselfi, hate, disappoint, fami...      1\n",
      "128612  [trappedtrap, trap, trap, trap, trap, trap, tr...      1\n",
      "136765  [fuck, fuckok, fuck, life, fuck, reason, haven...      1\n",
      "137933  [get, piec, shiti, hate, hate, hate, hate, hat...      1\n",
      "145233  [damn, like, imagin, girl, dick, bring, endles...      0\n",
      "145779  [want, see, world, burn, hate, world, hate, fu...      1\n",
      "160290  [hurtsit, hurt, dont, feel, love, hurt, outsid...      1\n",
      "168887  [kill, myselfim, kill, kill, kill, kill, kill,...      1\n",
      "169194  [wan, diei, wan, die, wan, die, wan, die, wan,...      1\n",
      "176749  [fuck, moneyfuck, money, fuck, money, fuck, mo...      1\n",
      "177340  [realiz, technic, incel, mean, incel, someon, ...      0\n",
      "178956  [hate, everyth, hate, everyth, hate, abl, casu...      0\n",
      "181623  [want, kill, want, kill, self, want, kill, wan...      1\n",
      "182628  [fuck, fuck, fuck, fuck, fuck, fuck, fuck, fuc...      0\n",
      "192277  [tire, fuck, expressionth, express, piss, ever...      1\n",
      "193597  [coordin, piss, version, piss, scott, hey, pis...      0\n",
      "193728  [peopl, middl, school, alreadi, sex, drug, alr...      1\n",
      "196853  [found, insult, wan, copi, past, everywher, hi...      0\n",
      "198481  [get, fuck, get, fuck, get, fuck, get, fuck, g...      0\n",
      "206371  [bore, bore, bore, bore, bore, bore, bore, bor...      0\n",
      "216159  [daughter, leav, idk, wtf, go, dowhat, daughte...      1\n",
      "221137  [fuck, fuck, fuck, fuck, fuck, fuck, fuck, fuc...      0\n",
      "228145  [kill, kill, kill, mekil, kill, kill, kill, ki...      1\n",
      "229271  [want, fuck, fuck, fuck, fuck, fuck, fuck, fuc...      0\n"
     ]
    }
   ],
   "source": [
    "extremely_negative = df_suicide_detection[df_suicide_detection['sentiment'].apply(lambda x: x['compound'] < -0.999)]\n",
    "\n",
    "print(\"Extremely negative:\")\n",
    "print(extremely_negative[['corpus', 'class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely positive:\n",
      "                                                   corpus  class\n",
      "4182    [talk, mei, need, need, help, need, help, need...      1\n",
      "15959   [read, love, love, love, love, love, love, lov...      0\n",
      "47127   [your, ever, sad, rememb, your, world, glam, p...      0\n",
      "51224   [remind, kid, eat, rich, eat, rich, eat, rich,...      0\n",
      "100524  [know, yall, struggl, wow, wow, wow, wow, wow,...      0\n",
      "102339  [unpopular, opinion, peopl, alway, think, life...      0\n",
      "128857  [good, day, pleas, thank, good, day, good, day...      0\n",
      "155407  [school, motto, kinda, cring, care, share, dar...      0\n",
      "170694  [copypasta, six, pardon, grammar, nasti, cough...      0\n",
      "172183  [need, helpi, need, help, need, help, need, he...      1\n",
      "173293  [pleas, help, mei, need, help, need, help, nee...      1\n",
      "177049  [mf, like, mf, like, mf, like, mf, like, mf, l...      0\n",
      "178533  [love, love, love, love, love, love, love, lov...      0\n",
      "214433  [pleas, help, mepleas, help, pleas, help, plea...      1\n"
     ]
    }
   ],
   "source": [
    "extremely_positive = df_suicide_detection[df_suicide_detection['sentiment'].apply(lambda x: x['compound'] > 0.999)]\n",
    "\n",
    "print(\"Extremely positive:\")\n",
    "print(extremely_positive[['corpus', 'class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremely positive cases include those belonging to the \"suicide\" class containing cries for help.  \n",
    "Sentiment correction for the word \"help\" nad \"please\" is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_sentiment(text, sentiment):\n",
    "    if 'help' in text or 'pleas' in text and sentiment>0:\n",
    "        return sentiment-0.3 \n",
    "    return sentiment \n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    text = \" \".join(text)\n",
    "    sentiment = sid.polarity_scores(text)\n",
    "    if 'help' in text or 'pleas' in text and sentiment>0:\n",
    "        sentiment['compound'] -= 0.3 \n",
    "    return sentiment\n",
    "\n",
    "df_suicide_detection['adjusted_sentiment'] = df_suicide_detection.apply(lambda row: adjust_sentiment(row['corpus'], row['sentiment']['compound']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_suicide</th>\n",
       "      <th>suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042554</td>\n",
       "      <td>-0.327974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   non_suicide   suicide\n",
       "0     0.042554 -0.327974"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df_suicide_detection.groupby(df_suicide_detection['class'])['adjusted_sentiment'].apply(list).reset_index()\n",
    "\n",
    "df_sentiment = pd.concat([\n",
    "    pd.DataFrame(grouped['adjusted_sentiment'].iloc[0]).mean(),\n",
    "    pd.DataFrame(grouped['adjusted_sentiment'].iloc[1]).mean()],\n",
    "axis=1,\n",
    ")\n",
    "df_sentiment.columns=['non_suicide','suicide']\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely positive:\n",
      "                                                   corpus  class\n",
      "15959   [read, love, love, love, love, love, love, lov...      0\n",
      "47127   [your, ever, sad, rememb, your, world, glam, p...      0\n",
      "51224   [remind, kid, eat, rich, eat, rich, eat, rich,...      0\n",
      "100524  [know, yall, struggl, wow, wow, wow, wow, wow,...      0\n",
      "102339  [unpopular, opinion, peopl, alway, think, life...      0\n",
      "155407  [school, motto, kinda, cring, care, share, dar...      0\n",
      "170694  [copypasta, six, pardon, grammar, nasti, cough...      0\n",
      "177049  [mf, like, mf, like, mf, like, mf, like, mf, l...      0\n",
      "178533  [love, love, love, love, love, love, love, lov...      0\n"
     ]
    }
   ],
   "source": [
    "extremely_positive = df_suicide_detection[df_suicide_detection['adjusted_sentiment'].apply(lambda x: x > 0.999)]\n",
    "\n",
    "print(\"Extremely positive:\")\n",
    "print(extremely_positive[['corpus', 'class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between text length and sentiment: -0.17658700948395203\n"
     ]
    }
   ],
   "source": [
    "correlation = pd.Series([len(x) for x in df_suicide_detection['corpus']]).corr(df_suicide_detection['adjusted_sentiment'])\n",
    "print(f\"Correlation between text length and sentiment: {correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation of -0.1765 suggests a weak but negative relationship between text length and sentiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d66d549bdef250af71f18e523f93ac3dcbb8bf027e6088d6eb631521c6a7e128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
