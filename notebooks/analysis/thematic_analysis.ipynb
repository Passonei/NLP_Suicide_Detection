{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suicide_detection = pd.read_csv('../../data/prepared/prepared.csv').drop('Unnamed: 0',axis=1)\n",
    "df_suicide_detection['corpus'] = df_suicide_detection['corpus'].apply(lambda x: x[1:-1].replace(\"'\", \"\").split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "X = vectorizer.fit_transform(df_suicide_detection['corpus'].apply(lambda x: ' '.join(x)))\n",
    "Y = df_suicide_detection['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_suicide = X[Y == 1]\n",
    "X_non_suicide = X[Y == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=5, max_iter=5, learning_method='online', random_state=42)\n",
    "lda_output = lda_model.fit_transform(X_suicide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suicide topic 1:\n",
      "['suicideive', 'ambien', 'meand', 'yourselfi', 'balding', 'meit', 'cowardice', 'everyonei', 'emptyi', 'coronavirus']\n",
      "Suicide topic 2:\n",
      "['caresi', 'plz', 'cyanide', 'coffin', 'friendsi', 'unimportant', 'peoplei', 'iam', 'canti', 'whywhy']\n",
      "Suicide topic 3:\n",
      "['loudly_crying_face', 'ativan', 'toim', 'penis', 'ibuprofen', 'aswell', 'anymoremy', 'dayi', 'blah', 'mg']\n",
      "Suicide topic 4:\n",
      "['people', 'time', 'ive', 'know', 'like', 'life', 'feel', 'dont', 'want', 'im']\n",
      "Suicide topic 5:\n",
      "['charcoal', 'worki', 'insulin', 'morei', 'rationally', 'euthanasia', 'survivor', 'sea', 'betteri', 'pleasei']\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in enumerate(lda_model.components_):\n",
    "    print(f\"Suicide topic {idx+1}:\")\n",
    "    print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=5, max_iter=5, learning_method='online', random_state=42)\n",
    "lda_output = lda_model.fit_transform(X_non_suicide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non suicide topic 1:\n",
      "['smirking_face', 'band', 'username', 'pog', 'america', 'racist', 'white', 'porn', 'men', 'ya']\n",
      "Non suicide topic 2:\n",
      "['homies', 'follower', 'face_with_tears_of_joy', 'lady', 'nut', 'cum', 'star', 'pensive_face', 'horny', 'filler']\n",
      "Non suicide topic 3:\n",
      "['cock', 'pleading_face', 'draw', 'smh', 'weary_face', 'u200b', 'loudly_crying_face', 'bro', 'smiling_face_with_sunglasses', 'flushed_face']\n",
      "Non suicide topic 4:\n",
      "['pc', 'taste', 'tiktok', 'playlist', 'drink', 'trans', 'assignment', 'listening', 'music', 'song']\n",
      "Non suicide topic 5:\n",
      "['friend', 'want', 'people', 'day', 'girl', 'know', 'na', 'guy', 'im', 'like']\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in enumerate(lda_model.components_):\n",
    "    print(f\"Non suicide topic {idx+1}:\")\n",
    "    print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texts related to suicide:\n",
    "1. Emotional themes: These texts are dominated by emotions of desperation, hopelessness, requests for help and mentions of death.\n",
    "2. Specific vocabulary: Contains words related to suicide methods, medications, and mental and emotional symptoms associated with suicidal thoughts.  \n",
    "3. Emptiness and desperation: They often mention emptiness, lack of meaning in life, and the desire to end life.\n",
    "\n",
    "Texts not related to suicide:\n",
    "1. Cultural Topics: Focus on internet culture, humor, interpersonal relationships, and popular trends.\n",
    "2. No mentions of suicide: They do not contain specific words related to suicidal thoughts or emotional aspects related to this topic.\n",
    "3. Everyday life and entertainment: They cover a variety of areas, from technology to everyday conversations and Internet interests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d66d549bdef250af71f18e523f93ac3dcbb8bf027e6088d6eb631521c6a7e128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
