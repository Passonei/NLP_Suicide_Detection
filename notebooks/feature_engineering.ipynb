{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/Suicide_Detection.csv', usecols=['text','class'])\n",
    "df['class'] = df['class'].map({'suicide': 1, 'non-suicide':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = [len(document.split()) for document in df['text']]\n",
    "exclamation = [len([char for char in document if char == '!']) for document in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/prepared/prepared.csv', index_col=0)\n",
    "df['corpus'] = df['corpus'].apply(lambda x: x[1:-1].replace(\"'\", \"\").split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment(text):\n",
    "        sentiment = sid.polarity_scores(\" \".join(text))\n",
    "        help_words = [\n",
    "        'help','suicide','plz', 'cyanide','ibuprofen','charcoal',\n",
    "        'euthanasia','survivor','please','unimportant', 'insulin',\n",
    "        'support', 'urgent', 'emergency']\n",
    "        \n",
    "        if any(word in text for word in help_words): \n",
    "            sentiment['compound'] *= 0.5\n",
    "        return [value for value in sentiment.values()]\n",
    "        \n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "sentiment = df['corpus'].apply(lambda x: get_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=4, lowercase=False)\n",
    "X = vectorizer.fit_transform(df['corpus'].apply(lambda x: ' '.join(x)))\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "keyword = [features[document.toarray().argsort()[0][::-1][:3]] for document in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = pd.DataFrame(length)\n",
    "exclamation = pd.DataFrame(exclamation)\n",
    "\n",
    "length = length[length.index.isin(df.index)]\n",
    "exclamation = exclamation[exclamation.index.isin(df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = pd.concat(\n",
    "    [length,\n",
    "    exclamation,\n",
    "    pd.DataFrame(sentiment.to_list(), index=df.index),\n",
    "    pd.Series(keyword, index=df.index),\n",
    "    df['class'],\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "df_feature.columns = ['length', 'exclamation', 'negative', 'neutral', 'positive', 'compound', 'keywords', 'class']\n",
    "df_feature.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "      <th>keywords</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.48700</td>\n",
       "      <td>[wife, threatening, cheated]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.09840</td>\n",
       "      <td>[compliment, affected, irl]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.20250</td>\n",
       "      <td>[swear, annoying, hear]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.265</td>\n",
       "      <td>-0.10115</td>\n",
       "      <td>[helpjust, cry, hard]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.49795</td>\n",
       "      <td>[anti, feeling, therapy]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232069</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.27550</td>\n",
       "      <td>[rock, anything, going]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232070</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.170</td>\n",
       "      <td>-0.34000</td>\n",
       "      <td>[deprived, count, nightmare]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232071</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.36120</td>\n",
       "      <td>[double_exclamation_mark, pee, salty]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232072</th>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-0.44715</td>\n",
       "      <td>[toughing, life, fucked]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232073</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.87040</td>\n",
       "      <td>[knight, hollow, beaten]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232023 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        length  exclamation  negative  neutral  positive  compound  \\\n",
       "0          143            0     0.398    0.441     0.161  -0.48700   \n",
       "1           27            0     0.225    0.529     0.245   0.09840   \n",
       "2           26            0     0.259    0.433     0.308   0.20250   \n",
       "3            9            0     0.441    0.294     0.265  -0.10115   \n",
       "4          438            0     0.361    0.513     0.126  -0.49795   \n",
       "...        ...          ...       ...      ...       ...       ...   \n",
       "232069      19            0     0.260    0.740     0.000  -0.27550   \n",
       "232070      31            0     0.298    0.532     0.170  -0.34000   \n",
       "232071      14            0     0.000    0.848     0.152   0.36120   \n",
       "232072     364            0     0.251    0.530     0.219  -0.44715   \n",
       "232073      33            0     0.427    0.491     0.082  -0.87040   \n",
       "\n",
       "                                     keywords  class  \n",
       "0                [wife, threatening, cheated]      1  \n",
       "1                 [compliment, affected, irl]      0  \n",
       "2                     [swear, annoying, hear]      0  \n",
       "3                       [helpjust, cry, hard]      1  \n",
       "4                    [anti, feeling, therapy]      1  \n",
       "...                                       ...    ...  \n",
       "232069                [rock, anything, going]      0  \n",
       "232070           [deprived, count, nightmare]      0  \n",
       "232071  [double_exclamation_mark, pee, salty]      0  \n",
       "232072               [toughing, life, fucked]      1  \n",
       "232073               [knight, hollow, beaten]      0  \n",
       "\n",
       "[232023 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.to_csv(\"../data/prepared/new_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d66d549bdef250af71f18e523f93ac3dcbb8bf027e6088d6eb631521c6a7e128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
